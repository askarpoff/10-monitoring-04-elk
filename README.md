# Домашнее задание к занятию 15 «Система сбора логов Elastic Stack»

## Задание 1

Вам необходимо поднять в докере и связать между собой:

- elasticsearch (hot и warm ноды);
- logstash;
- kibana;
- filebeat.

Logstash следует сконфигурировать для приёма по tcp json-сообщений.

Filebeat следует сконфигурировать для отправки логов docker вашей системы в logstash.

В директории help находится манифест docker-compose и конфигурации filebeat/logstash для быстрого 
выполнения этого задания.

Результатом выполнения задания должны быть:

- скриншот `docker ps` через 5 минут после старта всех контейнеров (их должно быть 5);
![image](https://user-images.githubusercontent.com/108946489/229453681-1253c572-9859-4c99-ae0c-a2d3301934e6.png)

- скриншот интерфейса kibana;
![image](https://user-images.githubusercontent.com/108946489/230662318-b49ee116-a265-46a6-b0b4-4c5b185c33a6.png))

- <strike>docker-compose манифест (если вы не использовали директорию help)</strike> немного допилил из help;
- <strike>ваши yml-конфигурации для стека (если вы не использовали директорию help)</strike> использовал готовый.

## Задание 2

Перейдите в меню [создания index-patterns  в kibana](http://localhost:5601/app/management/kibana/indexPatterns/create) и создайте несколько index-patterns из имеющихся.
![image](https://user-images.githubusercontent.com/108946489/230662832-6839525e-250d-498f-90d1-89e02356935b.png)

Перейдите в меню просмотра логов в kibana (Discover) и самостоятельно изучите, как отображаются логи и как производить поиск по логам.

В манифесте директории help также приведенно dummy-приложение, которое генерирует рандомные события в stdout-контейнера.
Эти логи должны порождать индекс logstash-* в elasticsearch. Если этого индекса нет — воспользуйтесь советами и источниками из раздела «Дополнительные ссылки» этого задания.
 
---
